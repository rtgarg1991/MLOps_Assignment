name: MLOps Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

permissions:
  id-token: write
  contents: read
  pull-requests: write

env:
  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  REGION: us-central1
  REPOSITORY: mlops-repo
  IMAGE_NAME: heart-trainer
  SERVING_IMAGE: heart-api
  BUCKET_NAME: mlops-final-001-mlops-artifacts
  CLUSTER_NAME: mlops-cluster
  ZONE: us-central1-a
  K8S_NAMESPACE: default

jobs:
  # 1. DETECT CHANGES
  changes:
    runs-on: ubuntu-latest
    outputs:
      data: ${{ steps.filter.outputs.data }}
      prep: ${{ steps.filter.outputs.prep }}
      feat: ${{ steps.filter.outputs.feat }}
      train: ${{ steps.filter.outputs.train }}
      api: ${{ steps.filter.outputs.api }}
    steps:
    - uses: actions/checkout@v4
    - uses: dorny/paths-filter@v3
      id: filter
      with:
        filters: |
          data: ['data/processed.cleveland.data', 'data/raw_version.txt']
          prep: ['src/pre-processing.py']
          feat: ['src/feature_engineering.py']
          # Training triggers if code, deps, or Dockerfile change
          train: ['src/train.py', 'requirements.txt', 'Dockerfile']
          # API triggers if main.py, deps, or serving Dockerfile change
          api: ['src/main.py', 'Dockerfile.serve', 'requirements.txt']

  # 2. BUILD TRAINER IMAGE
  build-trainer:
    needs: changes
    if: ${{ needs.changes.outputs.data == 'true' || needs.changes.outputs.prep == 'true' || needs.changes.outputs.feat == 'true' || needs.changes.outputs.train == 'true' }}
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - id: 'auth'
      uses: 'google-github-actions/auth@v2'
      with:
        workload_identity_provider: ${{ secrets.GCP_WIF_PROVIDER }}
        service_account: ${{ secrets.GCP_SA_EMAIL }}

    - name: Configure Docker
      run: gcloud auth configure-docker $REGION-docker.pkg.dev

    - name: Build and Push Trainer
      run: |
        docker build -f Dockerfile -t $REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE_NAME:${{ github.sha }} .
        docker push $REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE_NAME:${{ github.sha }}

  # 3. RUN PIPELINE JOBS
  run-pipeline:
    needs: [changes, build-trainer]
    # Run if build-trainer succeeded.
    # OR if it's a PUSH (Merge) but we need to run deploy-api even if training skipped.
    if: ${{ always() && (needs.build-trainer.result == 'success' || github.event_name == 'push') }}
    runs-on: ubuntu-latest
    outputs:
      pr_num: ${{ steps.vars.outputs.pr_num_output }}

    steps:
    - uses: actions/checkout@v4

    - uses: google-github-actions/auth@v2
      with:
        workload_identity_provider: ${{ secrets.GCP_WIF_PROVIDER }}
        service_account: ${{ secrets.GCP_SA_EMAIL }}

    - uses: google-github-actions/setup-gcloud@v2
    - uses: google-github-actions/get-gke-credentials@v2
      with:
        cluster_name: ${{ env.CLUSTER_NAME }}
        location: ${{ env.ZONE }}

    - name: Install envsubst
      run: sudo apt-get install -y gettext-base

    - name: Set Variables
      id: vars
      run: |
        echo "SHORT_SHA=$(echo ${{ github.sha }} | cut -c1-7)" >> $GITHUB_ENV

        if [[ "${{ github.event_name }}" == "pull_request" ]]; then
          echo "PR_NUMBER=${{ github.event.number }}" >> $GITHUB_ENV
          echo "pr_num_output=${{ github.event.number }}" >> $GITHUB_OUTPUT
          echo "MODE=experiment" >> $GITHUB_ENV
        else
          COMMIT_MSG=$(git log -1 --pretty=%B)
          PR_NUM=$(echo "$COMMIT_MSG" | grep -oP '#\K\d+' | head -1 || echo "")

          if [ -z "$PR_NUM" ]; then
            PR_NUM="0"
          fi

          echo "PR_NUMBER=$PR_NUM" >> $GITHUB_ENV
          echo "pr_num_output=$PR_NUM" >> $GITHUB_OUTPUT
          echo "MODE=full_training" >> $GITHUB_ENV
        fi

    # --- A. INGESTION ---
    - name: Run Ingest
      if: needs.changes.outputs.data == 'true'
      run: |
        export JOB_NAME=ingest-$SHORT_SHA
        export CMD='["python", "src/ingest.py"]'
        export ARGS='["--bucket='${BUCKET_NAME}'", "--pr-number='${PR_NUMBER}'"]'
        export IMAGE=$REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE_NAME:${{ github.sha }}

        envsubst < k8s/universal-job.yaml | kubectl apply -f -
        kubectl wait --for=condition=complete job/$JOB_NAME --timeout=5m

    # --- B. PRE-PROCESSING ---
    - name: Run Pre-processing
      if: needs.changes.outputs.data == 'true' || needs.changes.outputs.prep == 'true'
      run: |
        export JOB_NAME=preprocess-$SHORT_SHA
        export CMD='["python", "src/pre-processing.py"]'
        export ARGS='["--bucket='${BUCKET_NAME}'", "--pr-number='${PR_NUMBER}'"]'
        export IMAGE=$REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE_NAME:${{ github.sha }}

        envsubst < k8s/universal-job.yaml | kubectl apply -f -
        kubectl wait --for=condition=complete job/$JOB_NAME --timeout=5m

    # --- C. FEATURE ENGINEERING ---
    - name: Run Feature Engineering
      if: needs.changes.outputs.data == 'true' || needs.changes.outputs.prep == 'true' || needs.changes.outputs.feat == 'true'
      run: |
        export JOB_NAME=feature-$SHORT_SHA
        export CMD='["python", "src/feature_engineering.py"]'
        export ARGS='["--bucket='${BUCKET_NAME}'", "--pr-number='${PR_NUMBER}'"]'
        export IMAGE=$REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE_NAME:${{ github.sha }}

        envsubst < k8s/universal-job.yaml | kubectl apply -f -
        kubectl wait --for=condition=complete job/$JOB_NAME --timeout=5m

    # --- D. PROMOTION ---
    - name: Promote Artifacts to Production
      if: github.event_name == 'push'
      run: |
        export JOB_NAME=promote-$SHORT_SHA
        export CMD='["python", "src/promote.py"]'
        export ARGS='["--bucket='${BUCKET_NAME}'", "--pr-number='${PR_NUMBER}'"]'
        export IMAGE=$REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE_NAME:${{ github.sha }}

        envsubst < k8s/universal-job.yaml | kubectl apply -f -
        kubectl wait --for=condition=complete job/$JOB_NAME --timeout=5m

    # --- E. TRAINING (Corrected Conditions) ---
    - name: Run Training
      # LOGIC:
      # 1. Run if ANY ML file changed (train, data, prep, feat).
      # 2. OR if it's a PR (we might want to experiment even if just config changed).
      if: |
        github.event_name == 'pull_request' ||
        (needs.changes.outputs.train == 'true' || needs.changes.outputs.data == 'true' || needs.changes.outputs.prep == 'true' || needs.changes.outputs.feat == 'true')
      run: |
        export JOB_NAME=train-$SHORT_SHA
        export BUCKET_NAME=${BUCKET_NAME}
        export MODE=${MODE}
        export PR_NUMBER=${PR_NUMBER}
        export IMAGE=$REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE_NAME:${{ github.sha }}

        envsubst '${JOB_NAME} ${BUCKET_NAME} ${MODE} ${PR_NUMBER} ${IMAGE}' < k8s/parallel-train-job.yaml | kubectl apply -f -

        kubectl wait --for=condition=complete job/$JOB_NAME --timeout=10m

    # --- F. REPORT RESULTS TO PR ---
    - name: Comment Results on PR
      if: github.event_name == 'pull_request'
      env:
        GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        JOB_NAME=train-$SHORT_SHA
        PODS=$(kubectl get pods -l job-name=$JOB_NAME -o name)

        if [ -z "$PODS" ]; then
          echo "No pods found for job $JOB_NAME"
          exit 0
        fi

        echo "" > raw_metrics.jsonl
        for pod in $PODS; do
            kubectl logs $pod | grep "__METRICS__:" | awk -F'__METRICS__:' '{print $2}' >> raw_metrics.jsonl || true
        done

        python3 -c "
        import json
        import sys

        print('### Model Training Results (GKE Jobs)')
        print('| Model Type | Accuracy | Run ID |')
        print('| :--- | :--- | :--- |')

        try:
            results = []
            with open('raw_metrics.jsonl') as f:
                for line in f:
                    if not line.strip(): continue
                    try:
                        results.append(json.loads(line))
                    except json.JSONDecodeError:
                        continue

            results.sort(key=lambda x: x.get('accuracy', 0), reverse=True)

            if not results:
                print('| No metrics found in logs | | |')
            else:
                for row in results:
                    m_type = row.get('model_type', 'N/A')
                    acc = row.get('accuracy', 0.0)
                    rid = row.get('run_id', 'N/A')
                    print(f'| {m_type} | {acc:.4f} | {rid} |')

        except FileNotFoundError:
            print('| No logs file generated | | |')
        " > body.md

        gh pr comment ${{ github.event.number }} --body-file body.md

  # 4. TEST API JOB
  test-api-dry-run:
    needs: changes
    if: ${{ needs.changes.outputs.api == 'true' || github.event_name == 'pull_request' }}
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Create Dummy Model Directory
      run: mkdir -p models

    - name: Build API Container
      run: docker build -f Dockerfile.serve -t heart-api-test:latest .

    - name: Start API
      run: |
        docker run -d -p 8000:8080 --name api-test heart-api-test:latest
        echo "Waiting for API to start..."
        sleep 20

    - name: Test Health Check
      run: |
        for i in {1..5}; do
          STATUS=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:8000/health || echo "fail")
          if [ "$STATUS" == "200" ]; then
            echo "Health check passed!"
            exit 0
          fi
          echo "Attempt $i: Health check failed ($STATUS). Retrying in 5s..."
          sleep 5
        done

        echo "Final failure. Container Logs:"
        docker logs api-test
        exit 1

    - name: Test Prediction Logic
      run: |
        curl -X POST "http://localhost:8000/predict" \
             -H "Content-Type: application/json" \
             -d '{
               "age": 63, "sex": 1, "cp": 3, "trestbps": 145, "chol": 233,
               "fbs": 1, "restecg": 0, "thalach": 150, "exang": 0,
               "oldpeak": 2.3, "slope": 0, "ca": 0, "thal": 1
             }' > response.json

        echo "Response:"
        cat response.json

        if grep -q "prediction" response.json; then
            echo "Prediction endpoint returned valid JSON"
        else
            echo "Prediction endpoint failed"
            docker logs api-test
            exit 1
        fi

  # 5. DEPLOY API
  deploy-api:
    needs: [changes, run-pipeline]
    if: github.event_name == 'push'
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - uses: google-github-actions/auth@v2
      with:
        workload_identity_provider: ${{ secrets.GCP_WIF_PROVIDER }}
        service_account: ${{ secrets.GCP_SA_EMAIL }}

    - uses: google-github-actions/setup-gcloud@v2

    - run: gcloud auth configure-docker $REGION-docker.pkg.dev
    - uses: google-github-actions/get-gke-credentials@v2
      with:
        cluster_name: ${{ env.CLUSTER_NAME }}
        location: ${{ env.ZONE }}

    - name: Download Model (Smart Fallback)
      env:
        PR_NUM: ${{ needs.run-pipeline.outputs.pr_num }}
      run: |
        echo "Checking for model v_${PR_NUM}..."
        mkdir -p models

        if gsutil ls gs://$BUCKET_NAME/production/model_v_${PR_NUM}/model.pkl; then
            echo "Found NEW model v_${PR_NUM}. Downloading..."
            gsutil cp gs://$BUCKET_NAME/production/model_v_${PR_NUM}/model.pkl models/model.pkl
        else
            echo "Training was skipped (No ML changes). Falling back to LATEST production model."

            LATEST_MODEL_DIR=$(gsutil ls -d gs://$BUCKET_NAME/production/model_v_*/ | sort -V | tail -n 1)

            echo "Downloading latest: $LATEST_MODEL_DIR"
            gsutil cp ${LATEST_MODEL_DIR}model.pkl models/model.pkl
        fi

    - name: Build & Push API
      run: |
        docker build -f Dockerfile.serve -t $REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$SERVING_IMAGE:latest .
        docker push $REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$SERVING_IMAGE:latest

    - name: Deploy Service
      run: |
        export SERVING_IMAGE_URI=$REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$SERVING_IMAGE:latest
        envsubst < k8s/deployment.yaml | kubectl apply -f -

        kubectl rollout restart deployment/heart-api