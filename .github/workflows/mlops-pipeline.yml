name: MLOps Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

permissions:
  id-token: write
  contents: read
  pull-requests: write

env:
  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  REGION: us-central1
  REPOSITORY: mlops-repo
  IMAGE_NAME: heart-trainer
  SERVING_IMAGE: heart-api
  BUCKET_NAME: mlops-final-001-mlops-artifacts
  CLUSTER_NAME: mlops-cluster
  ZONE: us-central1-a
  K8S_NAMESPACE: default 

jobs:
  # 1. DETECT CHANGES
  changes:
    runs-on: ubuntu-latest
    outputs:
      data: ${{ steps.filter.outputs.data }}
      prep: ${{ steps.filter.outputs.prep }}
      feat: ${{ steps.filter.outputs.feat }}
      train: ${{ steps.filter.outputs.train }}
    steps:
    - uses: actions/checkout@v4
    - uses: dorny/paths-filter@v3
      id: filter
      with:
        filters: |
          data: ['data/processed.cleveland.data', 'data/raw_version.txt']
          prep: ['src/pre-processing.py']
          feat: ['src/feature_engineering.py']
          train: ['src/train.py']

  # 2. BUILD TRAINER IMAGE
  build-trainer:
    needs: changes
    if: ${{ needs.changes.outputs.data == 'true' || needs.changes.outputs.prep == 'true' || needs.changes.outputs.feat == 'true' || needs.changes.outputs.train == 'true' || github.event_name == 'push' }}
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - id: 'auth'
      uses: 'google-github-actions/auth@v2'
      with:
        workload_identity_provider: ${{ secrets.GCP_WIF_PROVIDER }}
        service_account: ${{ secrets.GCP_SA_EMAIL }}

    - name: Configure Docker
      run: gcloud auth configure-docker $REGION-docker.pkg.dev

    - name: Build and Push Trainer
      run: |
        docker build -f Dockerfile -t $REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE_NAME:${{ github.sha }} .
        docker push $REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE_NAME:${{ github.sha }}

  # 3. RUN PIPELINE JOBS
  run-pipeline:
    needs: [changes, build-trainer]
    if: ${{ always() && (needs.build-trainer.result == 'success' || github.event_name == 'push') }}
    runs-on: ubuntu-latest

    # OUTPUTS: Passing the calculated PR number to the next job
    outputs:
      pr_num: ${{ steps.vars.outputs.pr_num_output }}

    steps:
    - uses: actions/checkout@v4

    - uses: google-github-actions/auth@v2
      with:
        workload_identity_provider: ${{ secrets.GCP_WIF_PROVIDER }}
        service_account: ${{ secrets.GCP_SA_EMAIL }}

    - uses: google-github-actions/setup-gcloud@v2
    - uses: google-github-actions/get-gke-credentials@v2
      with:
        cluster_name: ${{ env.CLUSTER_NAME }}
        location: ${{ env.ZONE }}

    - name: Install envsubst
      run: sudo apt-get install -y gettext-base

    - name: Set Variables
      id: vars
      run: |
        echo "SHORT_SHA=$(echo ${{ github.sha }} | cut -c1-7)" >> $GITHUB_ENV

        if [[ "${{ github.event_name }}" == "pull_request" ]]; then
          echo "PR_NUMBER=${{ github.event.number }}" >> $GITHUB_ENV
          echo "pr_num_output=${{ github.event.number }}" >> $GITHUB_OUTPUT
          echo "MODE=experiment" >> $GITHUB_ENV
        else
          COMMIT_MSG=$(git log -1 --pretty=%B)
          PR_NUM=$(echo "$COMMIT_MSG" | grep -oP '#\K\d+' | head -1 || echo "")
  
          if [ -z "$PR_NUM" ]; then
            PR_NUM="0"
          fi
  
          echo "PR_NUMBER=$PR_NUM" >> $GITHUB_ENV
          echo "pr_num_output=$PR_NUM" >> $GITHUB_OUTPUT
          echo "MODE=full_training" >> $GITHUB_ENV
        fi

    # --- A. INGESTION ---
    - name: Run Ingest
      if: needs.changes.outputs.data == 'true'
      run: |
        export JOB_NAME=ingest-$SHORT_SHA
        export CMD='["python", "src/ingest.py"]'
        export ARGS='["--bucket='${BUCKET_NAME}'", "--pr-number='${PR_NUMBER}'"]'
        export IMAGE=$REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE_NAME:${{ github.sha }}

        envsubst < k8s/universal-job.yaml | kubectl apply -f -
        kubectl wait --for=condition=complete job/$JOB_NAME --timeout=5m

    # --- B. PRE-PROCESSING ---
    - name: Run Pre-processing
      if: needs.changes.outputs.data == 'true' || needs.changes.outputs.prep == 'true'
      run: |
        export JOB_NAME=preprocess-$SHORT_SHA
        export CMD='["python", "src/pre-processing.py"]'
        export ARGS='["--bucket='${BUCKET_NAME}'", "--pr-number='${PR_NUMBER}'"]'
        export IMAGE=$REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE_NAME:${{ github.sha }}

        envsubst < k8s/universal-job.yaml | kubectl apply -f -
        kubectl wait --for=condition=complete job/$JOB_NAME --timeout=5m

    # --- C. FEATURE ENGINEERING ---
    - name: Run Feature Engineering
      if: needs.changes.outputs.data == 'true' || needs.changes.outputs.prep == 'true' || needs.changes.outputs.feat == 'true'
      run: |
        export JOB_NAME=feature-$SHORT_SHA
        export CMD='["python", "src/feature_engineering.py"]'
        export ARGS='["--bucket='${BUCKET_NAME}'", "--pr-number='${PR_NUMBER}'"]'
        export IMAGE=$REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE_NAME:${{ github.sha }}

        envsubst < k8s/universal-job.yaml | kubectl apply -f -
        kubectl wait --for=condition=complete job/$JOB_NAME --timeout=5m

    # --- D. PROMOTION ---
    - name: Promote Artifacts to Production
      if: github.event_name == 'push'
      run: |
        export JOB_NAME=promote-$SHORT_SHA
        export CMD='["python", "src/promote.py"]'
        export ARGS='["--bucket='${BUCKET_NAME}'", "--pr-number='${PR_NUMBER}'"]'
        export IMAGE=$REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE_NAME:${{ github.sha }}

        envsubst < k8s/universal-job.yaml | kubectl apply -f -
        kubectl wait --for=condition=complete job/$JOB_NAME --timeout=5m

    # --- E. TRAINING ---
    - name: Run Training
      run: |
        export JOB_NAME=train-$SHORT_SHA
        export BUCKET_NAME=${BUCKET_NAME}
        export MODE=${MODE}
        export PR_NUMBER=${PR_NUMBER}
        export IMAGE=$REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE_NAME:${{ github.sha }}

        envsubst '${JOB_NAME} ${BUCKET_NAME} ${MODE} ${PR_NUMBER} ${IMAGE}' < k8s/parallel-train-job.yaml | kubectl apply -f -

        kubectl wait --for=condition=complete job/$JOB_NAME --timeout=10m

    # --- F. REPORT RESULTS TO PR ---
    - name: Comment Results on PR
      if: github.event_name == 'pull_request'
      env:
        GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        JOB_NAME=train-$SHORT_SHA
        PODS=$(kubectl get pods -l job-name=$JOB_NAME -o name)

        if [ -z "$PODS" ]; then
          echo "No pods found for job $JOB_NAME"
          exit 0
        fi

        echo "" > raw_metrics.jsonl
        for pod in $PODS; do
            kubectl logs $pod | grep "__METRICS__:" | awk -F'__METRICS__:' '{print $2}' >> raw_metrics.jsonl || true
        done

        python3 -c "
        import json
        import sys

        print('### ðŸ§ª Model Training Results (GKE Jobs)')
        print('| Model Type | Accuracy | Run ID |')
        print('| :--- | :--- | :--- |')

        try:
            results = []
            with open('raw_metrics.jsonl') as f:
                for line in f:
                    if not line.strip(): continue
                    try:
                        results.append(json.loads(line))
                    except json.JSONDecodeError:
                        continue

            results.sort(key=lambda x: x.get('accuracy', 0), reverse=True)

            if not results:
                print('| _No metrics found in logs_ | | |')
            else:
                for row in results:
                    m_type = row.get('model_type', 'N/A')
                    acc = row.get('accuracy', 0.0)
                    rid = row.get('run_id', 'N/A')
                    print(f'| {m_type} | {acc:.4f} | {rid} |')

        except FileNotFoundError:
            print('| _No logs file generated_ | | |')
        " > body.md

        gh pr comment ${{ github.event.number }} --body-file body.md

  # 4. DEPLOY API
  deploy-api:
    needs: run-pipeline
    if: github.event_name == 'push'
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - uses: google-github-actions/auth@v2
      with:
        workload_identity_provider: ${{ secrets.GCP_WIF_PROVIDER }}
        service_account: ${{ secrets.GCP_SA_EMAIL }}
    
    # Now set up gcloud/gsutil with these credentials
    - uses: google-github-actions/setup-gcloud@v2

    - run: gcloud auth configure-docker $REGION-docker.pkg.dev
    
    - uses: google-github-actions/get-gke-credentials@v2
      with:
        cluster_name: ${{ env.CLUSTER_NAME }}
        location: ${{ env.ZONE }}

    - name: Download Production Model
      # Using the Output from the previous job
      env:
        PR_NUM: ${{ needs.run-pipeline.outputs.pr_num }}
      run: |
        echo "Using PR_NUM: $PR_NUM"
        mkdir -p models
        # This will now work because 'setup-gcloud' configured the credentials above
        gsutil cp gs://$BUCKET_NAME/production/model_v_${PR_NUM}/model.pkl models/model.pkl

    - name: Build & Push API
      run: |
        docker build -f Dockerfile.serve -t $REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$SERVING_IMAGE:latest .
        docker push $REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$SERVING_IMAGE:latest

    - name: Deploy Service
      run: |
        export SERVING_IMAGE_URI=$REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$SERVING_IMAGE:latest
        envsubst < k8s/deployment.yaml | kubectl apply -f -

        kubectl apply -f k8s/service.yaml
        kubectl rollout restart deployment/heart-api