name: MLOps Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

permissions:
  id-token: write
  contents: read

env:
  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  REGION: us-central1
  REPOSITORY: mlops-repo
  IMAGE_NAME: heart-trainer
  SERVING_IMAGE: heart-api
  BUCKET_NAME: mlops-final-001-mlops-artifacts
  CLUSTER_NAME: mlops-cluster
  ZONE: us-central1-a
  # This namespace must match where you set up the KSA/Workload Identity
  K8S_NAMESPACE: default 

jobs:
  # 1. DETECT CHANGES
  # Identifies which files changed to trigger only necessary steps
  changes:
    runs-on: ubuntu-latest
    outputs:
      data: ${{ steps.filter.outputs.data }}
      prep: ${{ steps.filter.outputs.prep }}
      feat: ${{ steps.filter.outputs.feat }}
      train: ${{ steps.filter.outputs.train }}
    steps:
    - uses: actions/checkout@v4
    - uses: dorny/paths-filter@v3
      id: filter
      with:
        filters: |
          data: ['data/processed.cleveland.data', 'data/raw_version.txt']
          prep: ['src/pre-processing.py']
          feat: ['src/feature_engineering.py']
          train: ['src/train.py']

  # 2. BUILD TRAINER IMAGE
  # Runs only if any ML code or data changed
  build-trainer:
    needs: changes
    if: ${{ needs.changes.outputs.data == 'true' || needs.changes.outputs.prep == 'true' || needs.changes.outputs.feat == 'true' || needs.changes.outputs.train == 'true' || github.event_name == 'push' }}
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    # Authenticate to Google Cloud
    - id: 'auth'
      uses: 'google-github-actions/auth@v2'
      with:
        workload_identity_provider: ${{ secrets.GCP_WIF_PROVIDER }}
        service_account: ${{ secrets.GCP_SA_EMAIL }}

    - name: Configure Docker
      run: gcloud auth configure-docker $REGION-docker.pkg.dev

    - name: Build and Push Trainer
      run: |
        docker build -f Dockerfile -t $REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE_NAME:${{ github.sha }} .
        docker push $REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE_NAME:${{ github.sha }}

  # 3. RUN PIPELINE JOBS
  # Orchestrates the modular scripts on GKE
  run-pipeline:
    needs: [changes, build-trainer]
    # Always run if we built an image, or if it's a merge to main (to run promotion)
    if: ${{ always() && (needs.build-trainer.result == 'success' || github.event_name == 'push') }}
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4

    # --- Setup & Auth ---
    - uses: google-github-actions/auth@v2
      with:
        workload_identity_provider: ${{ secrets.GCP_WIF_PROVIDER }}
        service_account: ${{ secrets.GCP_SA_EMAIL }}

    - uses: google-github-actions/setup-gcloud@v2
    - uses: google-github-actions/get-gke-credentials@v2
      with:
        cluster_name: ${{ env.CLUSTER_NAME }}
        location: ${{ env.ZONE }}

    - name: Install envsubst
      run: sudo apt-get install -y gettext-base

    # --- Determine Variables ---
    - name: Set Variables
      id: vars
      run: |
        # 1. Short SHA
        echo "SHORT_SHA=$(echo ${{ github.sha }} | cut -c1-7)" >> $GITHUB_ENV
        
        # 2. Determine PR Number & Mode
        if [[ "${{ github.event_name }}" == "pull_request" ]]; then
          echo "Event is Pull Request. Using Number: ${{ github.event.number }}"
          echo "PR_NUMBER=${{ github.event.number }}" >> $GITHUB_ENV
          echo "MODE=experiment" >> $GITHUB_ENV
        else
          echo "Event is Push. Checking commit message for PR number..."
          # Get commit message
          COMMIT_MSG=$(git log -1 --pretty=%B)
          echo "Commit Message: $COMMIT_MSG"
          
          # Try to extract number (looks for #123)
          PR_NUM=$(echo "$COMMIT_MSG" | grep -oP '#\K\d+' | head -1 || echo "")
          
          # Force default to 0 if empty
          if [ -z "$PR_NUM" ]; then
            echo "No PR number found. Defaulting to 0."
            PR_NUM="0"
          else
            echo "Found PR Number: $PR_NUM"
          fi
          
          echo "PR_NUMBER=$PR_NUM" >> $GITHUB_ENV
          echo "MODE=full_training" >> $GITHUB_ENV
        fi

    # --- A. INGESTION (Only if data changed) ---
    - name: Run Ingest
      if: needs.changes.outputs.data == 'true'
      run: |
        export JOB_NAME=ingest-$SHORT_SHA
        export CMD='["python", "src/ingest.py"]'
        export ARGS='["--bucket='${BUCKET_NAME}'", "--pr-number='${PR_NUMBER}'"]'
        export IMAGE=$REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE_NAME:${{ github.sha }}
        
        envsubst < k8s/universal-job.yaml | kubectl apply -f -
        kubectl wait --for=condition=complete job/$JOB_NAME --timeout=5m

    # --- B. PRE-PROCESSING (If data OR prep script changed) ---
    - name: Run Pre-processing
      if: needs.changes.outputs.data == 'true' || needs.changes.outputs.prep == 'true'
      run: |
        export JOB_NAME=preprocess-$SHORT_SHA
        export CMD='["python", "src/pre-processing.py"]'
        export ARGS='["--bucket='${BUCKET_NAME}'", "--pr-number='${PR_NUMBER}'"]'
        export IMAGE=$REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE_NAME:${{ github.sha }}
        
        envsubst < k8s/universal-job.yaml | kubectl apply -f -
        kubectl wait --for=condition=complete job/$JOB_NAME --timeout=5m

    # --- C. FEATURE ENGINEERING (If data, prep OR feat script changed) ---
    - name: Run Feature Engineering
      if: needs.changes.outputs.data == 'true' || needs.changes.outputs.prep == 'true' || needs.changes.outputs.feat == 'true'
      run: |
        export JOB_NAME=feature-$SHORT_SHA
        export CMD='["python", "src/feature_engineering.py"]'
        export ARGS='["--bucket='${BUCKET_NAME}'", "--pr-number='${PR_NUMBER}'"]'
        export IMAGE=$REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE_NAME:${{ github.sha }}
        
        envsubst < k8s/universal-job.yaml | kubectl apply -f -
        kubectl wait --for=condition=complete job/$JOB_NAME --timeout=5m

    # --- D. PROMOTION (Only on Push to Main) ---
    - name: Promote Artifacts to Production
      if: github.event_name == 'push'
      run: |
        export JOB_NAME=promote-$SHORT_SHA
        export CMD='["python", "src/promote.py"]'
        export ARGS='["--bucket='${BUCKET_NAME}'", "--pr-number='${PR_NUMBER}'"]'
        # Use latest image or specific SHA if available
        export IMAGE=$REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE_NAME:${{ github.sha }}
        
        envsubst < k8s/universal-job.yaml | kubectl apply -f -
        kubectl wait --for=condition=complete job/$JOB_NAME --timeout=5m

    # --- E. TRAINING (Always runs in PR or Push) ---
    - name: Run Training
      run: |
        export JOB_NAME=train-$SHORT_SHA
        export BUCKET_NAME=${BUCKET_NAME}
        export MODE=${MODE}
        export PR_NUMBER=${PR_NUMBER}
        export IMAGE=$REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE_NAME:${{ github.sha }}
        
        # FIX: Pass specific variables to envsubst so it ignores $JOB_COMPLETION_INDEX and $MODEL_TYPE
        envsubst '${JOB_NAME} ${BUCKET_NAME} ${MODE} ${PR_NUMBER} ${IMAGE}' < k8s/parallel-train-job.yaml | kubectl apply -f -
        
        kubectl wait --for=condition=complete job/$JOB_NAME --timeout=10m

    # --- F. REPORT RESULTS TO PR (New Step) ---
    - name: Comment Results on PR
      # Only run on Pull Requests, not on push to main
      if: github.event_name == 'pull_request'
      env:
        GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        # 1. Query BigQuery for the latest results of this PR
        # We fetch the top 2 rows sorted by timestamp desc to get the run we just finished
        bq query --nouse_legacy_sql --format=json \
          "SELECT model_type, accuracy, run_id FROM \`$PROJECT_ID.ml_metadata.experiments\` WHERE pr_number = $PR_NUMBER ORDER BY timestamp DESC LIMIT 2" > results.json

        # 2. Parse JSON and format Markdown Table using Python one-liner
        # Generates a file body.md
        python3 -c "
        import json
        try:
            with open('results.json') as f:
                data = json.load(f)
            print('### Model Training Results')
            print('| Model Type | Accuracy | Run ID |')
            print('| :--- | :--- | :--- |')
              for row in data:
                print(f'| {row['model_type']} | {row['accuracy']:.4f} | {row['run_id']} |')
        except Exception as e:
            print('No results found or error parsing.')
        " > body.md

        # 3. Post Comment using GitHub CLI (Pre-installed on Runners)
        gh pr comment ${{ github.event.number }} --body-file body.md

  # 4. DEPLOY API (Only on Push to Main)
  deploy-api:
    needs: run-pipeline
    if: github.event_name == 'push'
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    # --- Auth ---
    - uses: google-github-actions/auth@v2
      with:
        workload_identity_provider: ${{ secrets.GCP_WIF_PROVIDER }}
        service_account: ${{ secrets.GCP_SA_EMAIL }}
    
    - run: gcloud auth configure-docker $REGION-docker.pkg.dev
    - uses: google-github-actions/get-gke-credentials@v2
      with:
        cluster_name: ${{ env.CLUSTER_NAME }}
        location: ${{ env.ZONE }}

    # --- Download Prod Model ---
    - name: Download Production Model
      run: |
        # PR_NUMBER logic same as above to find which version to download
        PR_NUM=$(git log -1 --pretty=%B | grep -oP '#\K\d+' | head -1 || echo "0")
        mkdir -p models
        # Pulling the specific version trained in the previous step
        gsutil cp gs://$BUCKET_NAME/production/model_v_${PR_NUM}/model.pkl models/model.pkl

    # --- Build & Push Serving Image ---
    - name: Build & Push API
      run: |
        docker build -f Dockerfile.serve -t $REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$SERVING_IMAGE:latest .
        docker push $REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$SERVING_IMAGE:latest

    # --- Deploy to GKE ---
    - name: Deploy Service
      run: |
        export SERVING_IMAGE_URI=$REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$SERVING_IMAGE:latest
        envsubst < k8s/deployment.yaml | kubectl apply -f -

        kubectl apply -f k8s/service.yaml
        kubectl rollout restart deployment/heart-api